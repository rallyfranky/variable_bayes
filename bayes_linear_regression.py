# -*- coding: utf-8 -*-
"""bayes linear regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/helical-sled-412813/locations/us-central1/repositories/25ae3fe7-401a-4946-8396-905c5cf59db9
"""

#pythonではじめるベイズ機会学習３章から

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#データ生成
true_w1 = 1.5
true_w2 = 0.8

#sample data
N = 4
x_data = np.random.uniform(-5, 5, size=N)
y_data = true_w1 * x_data + true_w2 + np.random.normal(0., 1., size=N)

#可視化
plot_x = np.linspace(-5, 5, 100)
plot_y = true_w1 * plot_x + true_w2

plt.figure(figsize=(10,6))
ax = plt.subplot()
ax.scatter(x_data, y_data, marker="o", label="sample_data")
ax.plot(plot_x, plot_y, color="black", label="assume")
plt.grid()
plt.legend()

#bayes model
import pymc as pm
import arviz as az

with pm.Model() as model:
  x = pm.Data('x', x_data)
  w1 = pm.Normal('w1', mu=0.0, sigma=10.0)
  w2 = pm.Normal('w2', mu=0.0, sigma=10.0)
  y = pm.Normal('y', mu=w1*x+w2, sigma=1.0, observed=y_data)

with model:
  trace = pm.sample(draws=3000, tune=1000, chains=3)

az.plot_trace(trace, compact=False)

az.plot_forest(trace, hdi_prob=0.95)

#サンプリングされたｗを使ってシミュレーションする
w1_plot = trace['posterior']['w1'].values.reshape(-1,1)
w2_plot = trace['posterior']['w2'].values.reshape(-1,1)

y_pred = plot_x * w1_plot + w2_plot

plt.figure(figsize=(10,6))
ax = plt.subplot()
ax.scatter(x_data, y_data, marker="o", label="sample_data")
ax.plot(plot_x, plot_y, color="black", label="assume")
plt.grid()
plt.legend()
for i in y_pred:
  plt.plot(plot_x, i, alpha=0.003, color="green")

#poisson regression model
from scipy import stats

#データ準備
N = 20
true_w1 = 0.8
true_w2 = 1.2

x_data = np.random.uniform(-3,3,N)
y_data = stats.poisson(mu=np.exp(true_w1*x_data+true_w2)).rvs()

x_plot = np.linspace(-3, 3, 100)
y_plot = stats.poisson(mu=np.exp(x_plot*true_w1+true_w2)).mean()

plt.figure(figsize=(8,4))
plt.scatter(x_data, y_data, label="sample")
plt.plot(x_plot, y_plot, label="True_model", linestyle="--", color="black")
plt.grid()
plt.legend()
plt.show()

with pm.Model() as model:
  x =  pm.Data('x', x_data)
  w1 = pm.Normal('w1', mu=0.0, sigma=1.0)
  w2 = pm.Normal('w2', mu=0.0, sigma=1.0)
  y = pm.Poisson('y', mu=pm.math.exp(w1*x+w2), observed=y_data)

with model:
  trace = pm.sample(draws=3000, tune=1000, chains=3)

pm.model_to_graphviz(model)

az.summary(trace)

az.plot_trace(trace, compact=False)

az.plot_posterior(trace, hdi_prob=0.95)

x_plot = np.linspace(-3,3,100)
w1_plot = trace['posterior']['w1'][:1].values.reshape(-1,1)
w2_plot = trace['posterior']['w2'][:1].values.reshape(-1,1)
y_plot = stats.poisson(mu=np.exp(w1_plot*x_plot+w2_plot)).mean()

plt.figure(figsize=(8,4))
plt.scatter(x_data, y_data, label="sample")

for i in y_pred:
  plt.plot(x_plot, i, alpha=0.01)

plt.grid()
plt.legend()
plt.show()

y_plot.shape

plt.figure(figsize=(8,4))
for i in y_plot:
  plt.plot(x_plot, i, color='green', alpha=0.003, label='assume')

plt.scatter(x_data, y_data, label="sample")

plt.grid()
plt.show()

#logistic regression

import seaborn as sns
iris_dataset = sns.load_dataset('iris')

N = 50
iris_dataset_2pecies = iris_dataset[iris_dataset['species'].isin(['setosa', 'versicolor'])].copy()

iris_dataset_use = iris_dataset_2pecies.sample(N, random_state=1)
x_data = iris_dataset_use[['sepal_length', 'sepal_width']].copy().values
x_data_add_bias = np.concatenate([x_data, np.ones((N,1))], axis=1)
y_data = pd.Categorical(iris_dataset_use['species']).codes

x_data_set = x_data[y_data==0]
x_data_ves = x_data[y_data==1]

y_data

fig, ax = plt.subplots(figsize=(8,4))
ax.scatter(x_data_set[:,0], x_data_set[:,1], color='darkred', marker='^', label='setosa')
ax.scatter(x_data_ves[:,0], x_data_ves[:,1], color='darkblue', marker='x', label='vesicolor')
ax.legend()
plt.tight_layout()
plt.show()

with pm.Model() as model:
  x = pm.Data('x', x_data_add_bias)
  w = pm.Normal('w', mu=0.0, sigma=1.0, shape=3)
  y = pm.Bernoulli('y', logit_p=w.dot(x.T), observed=y_data)

with model:
  trace = pm.sample(draws=3000, tune=1000, chains=3, return_inferencedata=True)

az.plot_trace(trace)

az.summary(trace)

#prediction
w_mcmc_samples = trace.posterior['w'].values.reshape(9000,3)

#　各次元ごとに取り出し
w1_samples = w_mcmc_samples[:,0]
w2_samples = w_mcmc_samples[:,1]
w3_samples = w_mcmc_samples[:,2]

fig, ax = plt.subplots(figsize=(8, 4))
# サンプルデータ
ax.scatter(x=x_data_set[:,0], y=x_data_set[:,1], color='darkred', marker='^',label='setosa')
ax.scatter(x=x_data_ves[:,0], y=x_data_ves[:,1], color='darkblue', marker='x', label='vesicolor')

N_new = 10
x1 = np.linspace(4.0, 7.2, N_new)
for i in range(0, 9000, 10):
  # x1に対してθ=0.5となるx2
  x2 = - w3_samples[i]/w2_samples[i]-w1_samples[i]/w2_samples[i]*x1
  ax.plot(x1, x2, alpha=0.01, color='black')
ax.set_xlabel('x1')
ax.set_ylabel('x2');
ax.legend()
plt.tight_layout()
ax.set_xlim(4.0, 7.2);ax.set_ylim(2.0, 4.5)

pm.model_to_graphviz(model)

#階層ベイズモデル
np.random.seed(12)
group_num = 9
data_num = 25

a_vector = np.random.normal(1000.0, scale=100.0, size=group_num)
b_vector = np.random.normal(50000.0, scale=500.0, size=group_num)

x_data = np.random.uniform(20, 50, data_num)

group_idx = np.random.randint(0, group_num, data_num)
y_data = a_vector[group_idx] * x_data + b_vector[group_idx] + np.random.normal(0, scale=1500.0, size=data_num)

x_data = np.append(x_data, 33.322)
y_data = np.append(y_data, 75004.54)
group_idx = np.append(group_idx, 8)

# # データ読み込み
#df_data = pd.read_csv('toy_data.csv')
# # 真の係数パラメータデータ
#df_coef = pd.read_csv('true_corf.csv')

df_data = pd.DataFrame([x_data, y_data, group_idx]).T
df_data.columns = ['x', 'y', 'systemID']

df_coef = pd.DataFrame([a_vector, b_vector]).T
df_coef.columns = ['a', 'b']

# 説明変数
x_data = df_data['x'].values
# 目的変数
y_data = df_data['y'].values
# 地域グループ
group_idx = df_data['systemID'].values.astype(int)
# 地域毎の傾きとバイアス
a_vector, b_vector = df_coef['a'].values, df_coef['b'].values

# 可視化用
x_linspace = np.linspace(20, 50, 100)

fig, ax = plt.subplots(figsize=(9, 6))
cm10 = plt.get_cmap('jet', 10)
for i in range(9):
  # 真の関数可視化
  ax.plot(x_linspace, a_vector[i]*x_linspace+b_vector[i], color=cm10(i+1), alpha=0.5)
  # 学習データ可視化
  ax.scatter(x_data[group_idx==i], y_data[group_idx==i], marker='.', color=cm10(i+1))

ax.set_xlabel('ha');ax.set_ylabel('price')
ax.set_title('region')
plt.tight_layout()

with pm.Model() as model:
  x = pm.Data('x', x_data)
#地域の傾き'a_offset'はa_mu,a_sigmaにより決定づけられる正規分布
  a_mu = pm.Normal('a_mu', mu=50.0, sigma=10.0)
  a_sigma = pm.HalfCauchy('a_sigma', beta=100.0)
  a_offset = pm.Normal('a_offset', mu=a_mu, sigma=a_sigma, shape=group_num)

#bias
  b_mu = pm.Normal('b_mu', mu=50000.0, sigma=1000.0)
  b_sigma = pm.HalfCauchy('b_sigma', beta=1000.0)
  b_offset = pm.Normal('b_offset', mu=b_mu, sigma=b_sigma, shape=group_num)

  y = pm.Normal('y', mu=a_offset[group_idx]*x+b_offset[group_idx], sigma=1000, observed=y_data)

with model:
  trace = pm.sample(draws=3000, tune=1000, chains=3, return_inferencedata=True)

pm.model_to_graphviz(model)

az.summary(trace)

az.plot_trace(trace, var_names=['a_mu', 'a_sigma', 'a_offset', 'b_mu', 'b_sigma', 'b_offset'])

#階層ベイズ事例
df = pd.read_csv('https://raw.githubusercontent.com/kenkenvw/data/main/mikan_pest_insect.csv')

#GLM~poisson_regression
#データの準備、A_agentとB_agent、園地のデータのみ使う
x_data = df[['orchard', 'A-agent', 'B-agent']]
y_data = df['count']
x_data['orchard'] = pd.Categorical(x_data['orchard']).codes
x_data['b0'] = 1
x_data = x_data.astype('float16')
y_data = y_data.astype('float16')

with pm.Model() as model:
  x = pm.Data('x', x_data)
  w = pm.Normal('w', mu=0.0, sigma=10, shape=4)
  y = pm.Poisson('y', mu=np.exp(w.dot(x.T)), observed=y_data)

with model:
  trace = pm.sample(draws=3000, tune=1000, chain=3)

pm.model_to_graphviz(model)

az.plot_posterior(trace)

az.plot_trace(trace, compact=False)

pm.summary(trace)

#ロケーション別に階層化
group_idx = pd.Categorical(df['location']).codes
x_data = x_data.drop(['b0'], axis=1, errors='ignore')

with pm.Model() as model2:
  x1 = pm.Data('x1', x_data['A-agent'])
  x2 = pm.Data('x2', x_data['B-agent'])
  x3 = pm.Data('x3', x_data['orchard'])
  w1_mu = pm.Normal('w1_mu', mu=0.0, sigma=10.0)
  w1_sigma = pm.HalfCauchy('w1_sigma', beta=10.0)
  w2_mu = pm.Normal('w2_mu', mu=0.0, sigma=10.0)
  w2_sigma = pm.HalfCauchy('w2_sigma', beta=10.0)
  w3_mu = pm.Normal('w3_mu', mu=0.0, sigma=10.0)
  w3_sigma = pm.HalfCauchy('w3_sigma', beta=10.0)
  w1 = pm.Normal('w1', mu=w1_mu, sigma=w1_sigma, shape=6)
  w2 = pm.Normal('w2', mu=w2_mu, sigma=w2_sigma, shape=6)
  w3 = pm.Normal('w3', mu=w3_mu, sigma=w3_sigma, shape=6)
  bias = pm.HalfCauchy('bias', beta=10.0)
  y = pm.Poisson('y', mu=np.exp(w1[group_idx]*x1 + w2[group_idx]*x2 + w3[group_idx]*x3 + bias), observed=y_data)

pm.model_to_graphviz(model2)

with model2:
  trace = pm.sample(draws=3000, tune=1000, chain=3)

az.summary(trace)

az.plot_trace(trace)

